{"basics":{"name":"Michael Diskin","label":"Head of LLM R&D","image":"","email":"michael.s.diskin@gmail.com","summary":"AI/ML leader with a track record of bridging top-tier research and large-scale production. Built and scaled LLM and embeddings organizations from the ground up (30+ people, 4–5 teams).","location":{"city":"Moscow","countryCode":"RU","region":"Russia"},"profiles":[{"network":"GitHub","username":"yhn112","url":"https://github.com/yhn112"},{"network":"LinkedIn","username":"yhn112","url":"https://www.linkedin.com/in/yhn112"}]},"work":[{"name":"Wildberries","position":"Head of LLM R&D","location":"Moscow, Russia","url":"https://www.wildberries.ru","startDate":"2024-01-01","summary":"Built LLM R&D org from scratch, managing a 500+ GPU cluster and defining platform strategy for LLM and embeddings company-wide.","highlights":["Built LLM R&D org from 0 to 30+ engineers (4–5 teams)","Shipped universal text embeddings and marketplace-scale MT for 10+ languages","Deployed optimized LLM serving — cut GPU costs by 40%+","Built RAG-powered assistants with safety guardrails and evaluation framework","Established research-to-production operating model"]},{"name":"Brask AI","position":"Senior Research Engineer","location":"Tbilisi, Georgia","url":"https://www.brask.ai","startDate":"2022-01-01","endDate":"2023-12-31","highlights":["Led R&D on a lip-sync model for AI video dubbing","Defined quality metrics and failure-analysis pipeline"]},{"name":"Yandex Research","position":"Research Scientist","location":"Moscow, Russia","url":"https://research.yandex.com","startDate":"2021-01-01","endDate":"2022-12-31","highlights":["5 papers at NeurIPS, ICML, and ICLR","Led pre-training of open-source Russian BERT-class language model","Created GNN benchmark under heterophily (400+ citations)"]},{"name":"Huawei","position":"Research Engineer","location":"Moscow, Russia","startDate":"2020-01-01","endDate":"2021-12-31","highlights":["Computer vision research: optical flow and depth estimation"]},{"name":"Early-stage startups","position":"ML / Software Engineer","location":"Moscow, Russia","startDate":"2019-01-01","endDate":"2020-12-31","highlights":["Built ML-powered backend services and data pipelines from scratch"]},{"name":"Yandex","position":"Software Engineering Intern","location":"Moscow, Russia","startDate":"2017-01-01","endDate":"2018-12-31","highlights":["Large-scale analytics over multi-terabyte log data using MapReduce (YT)"]}],"education":[{"institution":"HSE University","location":"Moscow, Russia","url":"https://www.hse.ru/en/","area":"Computer Science","studyType":"MSc","startDate":"2022-01-01","endDate":"2024-01-01","score":"summa cum laude"},{"institution":"Yandex School of Data Analysis","url":"https://yandexdataschool.com","area":"Machine Learning","studyType":"Graduate program","startDate":"2019-01-01","endDate":"2021-01-01"},{"institution":"HSE University","location":"Moscow, Russia","url":"https://www.hse.ru/en/","area":"Computer Science","studyType":"BSc","startDate":"2014-01-01","endDate":"2019-01-01"}],"awards":[{"title":"HSE FCS Scholarship for Research Excellence","date":"2024-01-01","awarder":"HSE University"},{"title":"Tinkoff Education Scholarship","date":"2023-01-01","awarder":"Tinkoff"},{"title":"Xeek.ai \"Put it on the Map!\" — 2nd place","date":"2020-01-01","awarder":"Xeek.ai","summary":"100+ teams, cash prize"},{"title":"Kaggle \"Recursion Cellular Image Classification\" — 13th of 800+ teams","date":"2019-06-01","awarder":"Kaggle"},{"title":"Huawei Image Inpainting Hackathon — 2nd place","date":"2019-03-01","awarder":"Huawei","summary":"100+ teams, cash prize"},{"title":"International Data Analysis Olympiad — 16th of 1000+","date":"2019-01-01","awarder":"IDAO"}],"skills":[{"name":"ML & AI","icon":"fa-solid fa-brain","keywords":["LLM pre-training & alignment","Parameter-efficient tuning (LoRA, QLoRA)","Text embeddings & rerankers","Machine translation","RAG pipelines","Multimodal vision-language models"]},{"name":"Frameworks","icon":"fa-solid fa-code","keywords":["PyTorch","Hugging Face","DeepSpeed","Megatron-LM","vLLM","Triton Inference Server","TensorRT-LLM"]},{"name":"Infra & MLOps","icon":"fa-solid fa-server","keywords":["CUDA","Docker","Kubernetes","Airflow","W&B","MLflow","Grafana / Prometheus"]},{"name":"Languages","icon":"fa-solid fa-terminal","keywords":["Python","C++","Bash","SQL"]}],"languages":[{"language":"Russian","fluency":"Native speaker"},{"language":"English","fluency":"Fluent"}],"publications":[{"name":"SWARM Parallelism: Training Large Models Can Be Surprisingly Communication-Efficient","publisher":"ICML 2023","releaseDate":"2023-01-01","url":"https://arxiv.org/abs/2301.11913"},{"name":"A Critical Look at the Evaluation of GNNs under Heterophily","publisher":"ICLR 2023","releaseDate":"2023-01-01","url":"https://arxiv.org/abs/2302.11640"},{"name":"Distributed Methods with Compressed Communication for Solving Variational Inequalities","publisher":"NeurIPS 2022","releaseDate":"2022-01-01","url":"https://arxiv.org/abs/2110.03313"},{"name":"Secure Distributed Training at Scale","publisher":"ICML 2022","releaseDate":"2022-01-01","url":"https://arxiv.org/abs/2106.11257"},{"name":"Distributed Deep Learning in Open Collaborations","publisher":"NeurIPS 2021","releaseDate":"2021-01-01","url":"https://arxiv.org/abs/2106.10207"}],"volunteer":[],"certificates":[],"interests":[],"references":[],"projects":[]}